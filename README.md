### Overview

This project contains two machine learning tasks focused on:

- Multi-Label Classification

- Noise Introduction and Removal using Machine Learning

Both tasks are implemented using the MNIST dataset (mnist_784) from OpenML.

- The goal is to understand how machine learning models behave when:

- Predicting multiple labels per sample

- Learning to reconstruct clean data from noisy inputs

### âœ… Task 1 â€” Multi-Label Classification
ğŸ¯ Objective

Convert the original MNIST digit labels into a multi-label format, then train a model to predict both labels simultaneously.

Instead of predicting:
```text
Digit = 7
```
We predict two properties:
```text
Odd or Not

Greater Than 5
```
Example:
```text
Digit	Odd	Greater Than 5
3	True	False
8	False	True
```
### ğŸ›  Methodology
1ï¸âƒ£ Load Dataset
```text
MNIST (70,000 images)

28x28 grayscale images (784 features)
```
2ï¸âƒ£ Convert Labels

Two binary labels were created:
```text
Odd = (digit % 2 == 1)

GreaterThan5 = (digit > 5)
```
3ï¸âƒ£ Model

Used:
```text
StandardScaler

OneVsRestClassifier

LogisticRegression
```
- Implemented inside a Pipeline to prevent data leakage.

4ï¸âƒ£ Evaluation Metrics

Since this is multi-label classification, I used:

- Precision

- Recall

- F1-Score

- Subset Accuracy (strict metric)

Subset Accuracy counts a sample as correct only if both labels are correct.

### ğŸ“Š Results

The model successfully learned both binary tasks simultaneously.

Multi-label classification allows a single input to have multiple outputs, which is useful in:

- Image tagging

- NLP tagging systems

- Recommendation systems

### âœ… Task 2 â€” Noise Removal Using Machine Learning
ğŸ¯ Objective

- Simulate noise in image data and train a model to reconstruct the original clean image.

This is a denoising regression problem.

### ğŸ›  Methodology
1ï¸âƒ£ Normalize Images

Pixel values scaled from:
```text
[0, 255] â†’ [0, 1]
```
2ï¸âƒ£ Add Gaussian Noise

Noise was introduced using:
```text
X_noisy = X_clean + Gaussian noise
```
Noise standard deviation controlled corruption strength.

3ï¸âƒ£ Model

Used:

- StandardScaler

- Ridge Regression

- Pipeline ensures:

Scaling learned from training data only

- No data leakage

The model learns:
```text
Noisy Image â†’ Clean Image
```text
4ï¸âƒ£ Evaluation Metrics
```
Used regression metrics:

- Mean Squared Error (MSE)

- Root Mean Squared Error (RMSE)

Lower RMSE indicates better reconstruction.

### ğŸ“ˆ Visualization

For evaluation, we plotted:

- Noisy image

- Reconstructed image

- Ground truth clean image

This visually demonstrates the modelâ€™s ability to remove noise.

### ğŸ§  Key Concepts Learned
ğŸ”¹ Multi-Label Classification
```text
One sample â†’ Multiple outputs
```
Different from multi-class classification.

ğŸ”¹ Data Leakage Prevention

- Split before scaling

- Fit scaler only on training data

- Use Pipeline for safety

ğŸ”¹ Noise Robustness

- Real-world datasets are often noisy.
- Machine learning models must handle corrupted or imperfect data.

ğŸ”¹ Denoising via Regression

- Mapping corrupted input back to clean output.

### ğŸ“¦ Requirements
```text
numpy
pandas
scikit-learn
matplotlib
seaborn
jupyter
```
Install using:
```text
pip install -r requirements.txt
```
